# 워크플로우의 이름
name: PostgreSQL DB 백업 및 S3 업로드

# 워크플로우가 실행될 이벤트를 정의합니다.
# 'workflow_dispatch'를 사용하여 GitHub UI에서 수동으로 워크플로우를 실행할 수 있습니다.
on:
  workflow_dispatch:

# 워크플로우에서 실행될 작업(Jobs)들을 정의합니다.
jobs:
  backup_postgres:
    # 이 작업이 실행될 환경을 지정합니다. 여기서는 최신 Ubuntu 환경을 사용합니다.
    runs-on: ubuntu-latest

    # 작업 전반에 걸쳐 사용될 환경 변수들을 정의합니다.
    # 이 값들을 실제 PostgreSQL 서버 및 AWS S3 정보로 반드시 변경해야 합니다.
    env:
      # PostgreSQL 연결 정보
      DB_HOST: <YOUR_ACTUAL_DB_HOST_OR_IP> # 예: 192.168.1.100 또는 myrdsinstance.abcdef.rds.amazonaws.com
      DB_PORT: 5432                       # PostgreSQL 포트 (기본 5432)
      DB_USER: <YOUR_ACTUAL_DB_USER>      # PostgreSQL 사용자명
      DB_NAME: <YOUR_ACTUAL_DB_NAME>      # 백업할 데이터베이스 이름
      PGPASSWORD: ${{ secrets.DB_PASSWORD }} # GitHub Secrets에 저장된 DB 비밀번호

      # AWS S3 정보
      AWS_REGION: ap-northeast-2           # S3 버킷이 위치한 AWS 리전
      S3_BUCKET_NAME: <YOUR_ACTUAL_S3_BUCKET_NAME> # 백업 파일을 업로드할 S3 버킷 이름

    # 이 작업에서 실행될 단계(Steps)들을 정의합니다.
    steps:
      - name: 📦 사전 준비: PostgreSQL 클라이언트 설치
        run: |
          echo "Installing PostgreSQL client..."
          sudo apt-get update
          sudo apt-get install -y postgresql-client
          echo "PostgreSQL client installed."

      - name: 🕒 타임스탬프 및 백업 파일 경로 설정
        id: set_vars # 이 단계의 출력 값을 다음 단계에서 참조하기 위한 ID
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          BACKUP_FILE_NAME="database_backup_${TIMESTAMP}.sql"
          
          # 백업 파일을 저장할 임시 디렉토리를 생성합니다.
          mkdir -p /tmp/db_backups
          BACKUP_FILE_PATH="/tmp/db_backups/${BACKUP_FILE_NAME}"
          
          # 다음 단계에서 사용할 수 있도록 출력 변수로 설정합니다.
          echo "BACKUP_FILE_PATH=${BACKUP_FILE_PATH}" >> "$GITHUB_OUTPUT"
          echo "BACKUP_FILE_NAME=${BACKUP_FILE_NAME}" >> "$GITHUB_OUTPUT"
          echo "TIMESTAMP=${TIMESTAMP}" >> "$GITHUB_OUTPUT"

      - name: 💾 PostgreSQL 데이터베이스 백업 (pg_dump)
        run: |
          echo "Starting PostgreSQL backup..."
          # pg_dump 명령을 사용하여 데이터베이스를 백업합니다.
          # PGPASSWORD 환경 변수를 통해 비밀번호를 안전하게 전달합니다.
          # 모든 변수는 큰따옴표로 감싸서 공백이나 특수 문자로 인한 오류를 방지합니다.
          pg_dump -h "${{ env.DB_HOST }}" -p "${{ env.DB_PORT }}" -U "${{ env.DB_USER }}" -d "${{ env.DB_NAME }}" > "${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}"
          
          echo "✅ PostgreSQL 백업 완료: ${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}"
          ls -lh "${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}" # 백업 파일 정보 확인

      # ---
      # - name: 🔐 백업 파일 암호화 (선택 사항)
      #   # 이 단계는 암호화 키 관리 전략에 따라 달라집니다.
      #   # 예시로 OpenSSL을 사용하지만, 실제 프로덕션에서는 더 안전한 방식을 고려해야 합니다.
      #   run: |
      #     echo "Encrypting backup file..."
      #     openssl enc -aes-256-cbc -salt -in "${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}" -out "${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}.enc" -k "${{ secrets.ENCRYPTION_KEY }}"
      #     rm "${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}" # 원본 파일 삭제
      #     echo "Backup file encrypted."
      #   continue-on-error: true # 암호화 실패 시에도 워크플로우 진행

      - name: ☁️ AWS 자격 증명 구성
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          
      - name: ⬆️ S3에 백업 업로드
        run: |
          echo "Uploading backup to S3..."
          # 백업 파일을 S3 버킷에 업로드합니다.
          # 암호화된 파일을 업로드하는 경우, 여기에서 .enc 확장자를 추가해야 합니다.
          aws s3 cp "${{ steps.set_vars.outputs.BACKUP_FILE_PATH }}" "s3://${{ env.S3_BUCKET_NAME }}/backups/${{ steps.set_vars.outputs.BACKUP_FILE_NAME }}"
          echo "✅ S3 업로드 완료: s3://${{ env.S3_BUCKET_NAME }}/backups/${{ steps.set_vars.outputs.BACKUP_FILE_NAME }}"

      - name: 🧹 로컬 백업 파일 정리
        if: always() # 이전 단계 실패 여부와 상관없이 항상 실행
        run: |
          echo "Cleaning up local backup files..."
          # 임시 백업 파일과 디렉토리를 삭제합니다.
          rm -rf /tmp/db_backups
          echo "✅ 로컬 백업 파일 정리 완료"

name: Build & Deploy finance-transactions with DB Backup + Provenance + Restart

on:
  workflow_dispatch:
  schedule:
    - cron: "*/5 * * * *"

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    env:
      GH_PAT: ${{ secrets.GH_PAT }}

    steps:
      - name: 📅 Checkout 코드
        uses: actions/checkout@v4

      - name: 📦 requirements.txt 생성 및 설치
        run: |
          echo "flask\nflask_sqlalchemy\npython-dotenv\npsycopg2-binary\nSQLAlchemy\nfaker" > requirements.txt
          pip install -r requirements.txt

      - name: ⚙️ .env 파일 생성
        run: |
          echo "FLASK_ENV=production" > .env
          echo "APP_NAME=FinanceTransactions" >> .env
          echo "DEBUG=False" >> .env
          echo "POSTGRES_DB=finance" >> .env
          echo "POSTGRES_USER=postgres" >> .env
          echo "POSTGRES_PASSWORD=postgres123" >> .env
          echo "DB_HOST=db" >> .env
          echo "DB_PORT=5432" >> .env

      - name: 🐍 글로벌 거래 원장 및 시뮬레이션 생성
        run: |
          mkdir -p .github/global .github/provenance
          python3 <<EOF
import csv, random, datetime, time, shutil
from faker import Faker
fake = Faker()

accounts = [[fake.name(), fake.bban(), round(random.uniform(1000,100000),2)] for _ in range(10)]
with open('.github/global/accounts.csv', 'w', newline='') as f:
    writer = csv.writer(f); writer.writerow(['name','account','balance']); writer.writerows(accounts)

# 거래 생성 (국가별 10건씩)
countries = ['KR', 'US', 'JP']
with open('.github/global/transactions.csv', 'w', newline='') as f:
    writer = csv.writer(f); writer.writerow(['timestamp','amount','currency','status'])
    for country in countries:
        for _ in range(10):
            ts = datetime.datetime.now().isoformat()
            amt = round(random.uniform(1.0, 5000.0), 2)
            currency = {'KR': 'KRW', 'US': 'USD', 'JP': 'JPY'}[country]
            status = random.choice(['completed','pending','failed'])
            writer.writerow([ts, amt, currency, status])
            time.sleep(0.01)

# 카드 거래
for card_type in ['credit_card', 'check_card']:
    with open(f'.github/global/{card_type}_transactions.csv', 'w', newline='') as f:
        writer = csv.writer(f); writer.writerow(['timestamp','card_number','amount','type','status'])
        for _ in range(15):
            ts = datetime.datetime.now().isoformat()
            card = fake.credit_card_number()
            amt = round(random.uniform(5.0, 300.0),2)
            t = random.choice(['withdrawal', 'deposit'])
            s = random.choice(['completed', 'pending', 'failed'])
            writer.writerow([ts, card, amt, t, s])

# 거래 재시도 처리
def retry(file):
    with open(file, 'r') as infile, open(file + '.tmp', 'w', newline='') as out:
        reader = csv.reader(infile); header = next(reader)
        writer = csv.writer(out); writer.writerow(header)
        for row in reader:
            if row[-1] in ['pending', 'failed']:
                row[-1] = 'completed'
            writer.writerow(row)
    shutil.move(file + '.tmp', file)

retry('.github/global/transactions.csv')
retry('.github/global/credit_card_transactions.csv')
retry('.github/global/check_card_transactions.csv')
EOF

      - name: 📊 거래 해시 기반 Provenance 생성
        run: |
          TS=$(date +%Y%m%d%H%M%S)
          mkdir -p .github/provenance
          OUT=".github/provenance/csv-metadata-$TS.json"
          echo "[" > "$OUT"
          for f in .github/global/*.csv; do
            HASH=$(sha256sum "$f" | awk '{print $1}')
            echo "  {\"file\": \"$f\", \"sha256\": \"$HASH\" }," >> "$OUT"
          done
          sed -i '$ s/},/}/' "$OUT"
          echo "]" >> "$OUT"

      - name: 🐘 PostgreSQL 컨테이너 실행 및 적재
        run: |
          docker run -d --name db \
            -e POSTGRES_DB=finance \
            -e POSTGRES_USER=postgres \
            -e POSTGRES_PASSWORD=postgres123 \
            -p 5432:5432 postgres:15
          sleep 10
          for f in transactions credit_card_transactions check_card_transactions; do
            tail -n +2 .github/global/${f}.csv > .github/global/tmp.csv
            if [ "$f" = "transactions" ]; then
              docker exec db psql -U postgres -d finance -c "CREATE TABLE IF NOT EXISTS ${f} (timestamp TIMESTAMP, amount NUMERIC, currency VARCHAR(10), status VARCHAR(20));"
              docker cp .github/global/tmp.csv db:/tmp/tmp.csv
              docker exec db psql -U postgres -d finance -c "COPY ${f}(timestamp, amount, currency, status) FROM '/tmp/tmp.csv' DELIMITER ',' CSV;"
            else
              docker exec db psql -U postgres -d finance -c "CREATE TABLE IF NOT EXISTS ${f} (timestamp TIMESTAMP, card_number VARCHAR(50), amount NUMERIC, type VARCHAR(30), status VARCHAR(20));"
              docker cp .github/global/tmp.csv db:/tmp/tmp.csv
              docker exec db psql -U postgres -d finance -c "COPY ${f}(timestamp, card_number, amount, type, status) FROM '/tmp/tmp.csv' DELIMITER ',' CSV;"
            fi
          done

      - name: 💾 DB 백업 및 증명서 작성
        run: |
          TS=$(date +%Y%m%d%H%M%S)
          docker exec db pg_dump -U postgres -d finance > .github/global/backup-$TS.sql
          echo "$TS" > .github/global/latest.txt
          HASH=$(sha256sum .github/global/backup-$TS.sql | awk '{print $1}')
          echo "{\"artifact\": \"backup-$TS.sql\", \"sha256\": \"$HASH\", \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" > .github/provenance/provenance-$TS.json

      - name: 🚀 GitHub Pages로 ledger + 증명서 자동 푸시
        if: env.GH_PAT != ''
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "github-actions"
          mkdir -p gh-pages
          cp .github/global/*.csv gh-pages/
          cp .github/provenance/*.json gh-pages/
          cd gh-pages
          git init
          git checkout -b gh-pages
          git remote add origin https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}
          git add .
          git commit -m "📊 Add global ledgers and provenance"
          git push --force origin gh-pages

      - name: 🔁 PostgreSQL 컨테이너 재기동
        if: always()
        run: |
          docker restart db || echo "[!] db 컨테이너 재시작 실패 (이미 종료됨)"
          sleep 5
